{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing \n",
    "## Objective\n",
    "In this Jupyter Notebook I will be focusing on:\n",
    "- Unzipping provided Data\n",
    "- Exploring the provided Data\n",
    "- Creating a Database to store data for further analysis\n",
    "- Prepare Data for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "import os #for interacting with path/directory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zippedData/tmdb.movies.csv\n",
      "zippedData/tn.movie_budgets.csv\n",
      "zippedData/imdb.name.basics.csv\n",
      "zippedData/imdb.title.principals.csv\n",
      "zippedData/title.akas.csv\n",
      "zippedData/bom.movie_gross.csv\n",
      "zippedData/imdb.title.basics.csv\n",
      "zippedData/title.ratings.csv\n"
     ]
    }
   ],
   "source": [
    "# Import data into jupyter notebook using glob\n",
    "csv_files = glob(\"zippedData/*.csv\")\n",
    "\n",
    "for file in csv_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary to store Data properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with file names as the Key\n",
    "# and their contents as the values\n",
    "# Clean up file names by getting rid or .csv & .tsv and replacing all '.' with '_'\n",
    "files_dict = {}\n",
    "for filename in csv_files:\n",
    "    filename_cleaned = os.path.basename(filename).replace('.csv', '').replace('.', '_')\n",
    "    filename_df = pd.read_csv(filename, index_col = 0)\n",
    "    files_dict[filename_cleaned] = filename_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmdb_movies\n",
      "tn_movie_budgets\n",
      "imdb_name_basics\n",
      "imdb_title_principals\n",
      "title_akas\n",
      "bom_movie_gross\n",
      "imdb_title_basics\n",
      "title_ratings\n"
     ]
    }
   ],
   "source": [
    "# Check Keys to make sure data is stored correctly\n",
    "for key in files_dict.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 genre_ids      id original_language  \\\n",
      "0          [12, 14, 10751]   12444                en   \n",
      "1      [14, 12, 16, 10751]   10191                en   \n",
      "2            [12, 28, 878]   10138                en   \n",
      "3          [16, 35, 10751]     862                en   \n",
      "4            [28, 878, 12]   27205                en   \n",
      "...                    ...     ...               ...   \n",
      "26512             [27, 18]  488143                en   \n",
      "26513             [18, 53]  485975                en   \n",
      "26514         [14, 28, 12]  381231                en   \n",
      "26515      [10751, 12, 28]  366854                en   \n",
      "26516             [53, 27]  309885                en   \n",
      "\n",
      "                                     original_title  popularity release_date  \\\n",
      "0      Harry Potter and the Deathly Hallows: Part 1      33.533   2010-11-19   \n",
      "1                          How to Train Your Dragon      28.734   2010-03-26   \n",
      "2                                        Iron Man 2      28.515   2010-05-07   \n",
      "3                                         Toy Story      28.005   1995-11-22   \n",
      "4                                         Inception      27.920   2010-07-16   \n",
      "...                                             ...         ...          ...   \n",
      "26512                         Laboratory Conditions       0.600   2018-10-13   \n",
      "26513                               _EXHIBIT_84xxx_       0.600   2018-05-01   \n",
      "26514                                  The Last One       0.600   2018-10-01   \n",
      "26515                                  Trailer Made       0.600   2018-06-22   \n",
      "26516                                    The Church       0.600   2018-10-05   \n",
      "\n",
      "                                              title  vote_average  vote_count  \n",
      "0      Harry Potter and the Deathly Hallows: Part 1           7.7       10788  \n",
      "1                          How to Train Your Dragon           7.7        7610  \n",
      "2                                        Iron Man 2           6.8       12368  \n",
      "3                                         Toy Story           7.9       10174  \n",
      "4                                         Inception           8.3       22186  \n",
      "...                                             ...           ...         ...  \n",
      "26512                         Laboratory Conditions           0.0           1  \n",
      "26513                               _EXHIBIT_84xxx_           0.0           1  \n",
      "26514                                  The Last One           0.0           1  \n",
      "26515                                  Trailer Made           0.0           1  \n",
      "26516                                    The Church           0.0           1  \n",
      "\n",
      "[26517 rows x 9 columns]\n",
      "    release_date                                        movie  \\\n",
      "id                                                              \n",
      "1   Dec 18, 2009                                       Avatar   \n",
      "2   May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
      "3    Jun 7, 2019                                 Dark Phoenix   \n",
      "4    May 1, 2015                      Avengers: Age of Ultron   \n",
      "5   Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi   \n",
      "..           ...                                          ...   \n",
      "78  Dec 31, 2018                                       Red 11   \n",
      "79   Apr 2, 1999                                    Following   \n",
      "80  Jul 13, 2005                Return to the Land of Wonders   \n",
      "81  Sep 29, 2015                         A Plague So Pleasant   \n",
      "82   Aug 5, 2005                            My Date With Drew   \n",
      "\n",
      "   production_budget domestic_gross worldwide_gross  \n",
      "id                                                   \n",
      "1       $425,000,000   $760,507,625  $2,776,345,279  \n",
      "2       $410,600,000   $241,063,875  $1,045,663,875  \n",
      "3       $350,000,000    $42,762,350    $149,762,350  \n",
      "4       $330,600,000   $459,005,868  $1,403,013,963  \n",
      "5       $317,000,000   $620,181,382  $1,316,721,747  \n",
      "..               ...            ...             ...  \n",
      "78            $7,000             $0              $0  \n",
      "79            $6,000        $48,482        $240,495  \n",
      "80            $5,000         $1,338          $1,338  \n",
      "81            $1,400             $0              $0  \n",
      "82            $1,100       $181,041        $181,041  \n",
      "\n",
      "[5782 rows x 5 columns]\n",
      "                  primary_name  birth_year  death_year  \\\n",
      "nconst                                                   \n",
      "nm0061671    Mary Ellen Bauder         NaN         NaN   \n",
      "nm0061865         Joseph Bauer         NaN         NaN   \n",
      "nm0062070           Bruce Baum         NaN         NaN   \n",
      "nm0062195         Axel Baumann         NaN         NaN   \n",
      "nm0062798          Pete Baxter         NaN         NaN   \n",
      "...                        ...         ...         ...   \n",
      "nm9990381         Susan Grobes         NaN         NaN   \n",
      "nm9990690          Joo Yeon So         NaN         NaN   \n",
      "nm9991320       Madeline Smith         NaN         NaN   \n",
      "nm9991786  Michelle Modigliani         NaN         NaN   \n",
      "nm9993380       Pegasus Envoy√©         NaN         NaN   \n",
      "\n",
      "                                         primary_profession  \\\n",
      "nconst                                                        \n",
      "nm0061671         miscellaneous,production_manager,producer   \n",
      "nm0061865        composer,music_department,sound_department   \n",
      "nm0062070                        miscellaneous,actor,writer   \n",
      "nm0062195  camera_department,cinematographer,art_department   \n",
      "nm0062798  production_designer,art_department,set_decorator   \n",
      "...                                                     ...   \n",
      "nm9990381                                           actress   \n",
      "nm9990690                                           actress   \n",
      "nm9991320                                           actress   \n",
      "nm9991786                                          producer   \n",
      "nm9993380                             director,actor,writer   \n",
      "\n",
      "                                  known_for_titles  \n",
      "nconst                                              \n",
      "nm0061671  tt0837562,tt2398241,tt0844471,tt0118553  \n",
      "nm0061865  tt0896534,tt6791238,tt0287072,tt1682940  \n",
      "nm0062070  tt1470654,tt0363631,tt0104030,tt0102898  \n",
      "nm0062195  tt0114371,tt2004304,tt1618448,tt1224387  \n",
      "nm0062798  tt0452644,tt0452692,tt3458030,tt2178256  \n",
      "...                                            ...  \n",
      "nm9990381                                      NaN  \n",
      "nm9990690                      tt9090932,tt8737130  \n",
      "nm9991320                      tt8734436,tt9615610  \n",
      "nm9991786                                      NaN  \n",
      "nm9993380                                tt8743182  \n",
      "\n",
      "[606648 rows x 5 columns]\n",
      "           ordering      nconst  category       job            characters\n",
      "tconst                                                                   \n",
      "tt0111414         1   nm0246005     actor       NaN           [\"The Man\"]\n",
      "tt0111414         2   nm0398271  director       NaN                   NaN\n",
      "tt0111414         3   nm3739909  producer  producer                   NaN\n",
      "tt0323808        10   nm0059247    editor       NaN                   NaN\n",
      "tt0323808         1   nm3579312   actress       NaN      [\"Beth Boothby\"]\n",
      "...             ...         ...       ...       ...                   ...\n",
      "tt9692684         1   nm0186469     actor       NaN  [\"Ebenezer Scrooge\"]\n",
      "tt9692684         2   nm4929530      self       NaN   [\"Herself\",\"Regan\"]\n",
      "tt9692684         3  nm10441594  director       NaN                   NaN\n",
      "tt9692684         4   nm6009913    writer    writer                   NaN\n",
      "tt9692684         5  nm10441595  producer  producer                   NaN\n",
      "\n",
      "[1028186 rows x 5 columns]\n",
      "           ordering                                    title region language  \\\n",
      "title_id                                                                       \n",
      "tt0369610        10                            –î–∂—É—Ä–∞—Å–∏–∫ —Å–≤—è—Ç     BG       bg   \n",
      "tt0369610        11                        Jurashikku warudo     JP      NaN   \n",
      "tt0369610        12  Jurassic World: O Mundo dos Dinossauros     BR      NaN   \n",
      "tt0369610        13                  O Mundo dos Dinossauros     BR      NaN   \n",
      "tt0369610        14                           Jurassic World     FR      NaN   \n",
      "...             ...                                      ...    ...      ...   \n",
      "tt9827784         2                       Sayonara kuchibiru    NaN      NaN   \n",
      "tt9827784         3                            Farewell Song    XWW       en   \n",
      "tt9880178         1                              La atenci√≥n    NaN      NaN   \n",
      "tt9880178         2                              La atenci√≥n     ES      NaN   \n",
      "tt9880178         3                            The Attention    XWW       en   \n",
      "\n",
      "                 types   attributes  is_original_title  \n",
      "title_id                                                \n",
      "tt0369610          NaN          NaN                0.0  \n",
      "tt0369610  imdbDisplay          NaN                0.0  \n",
      "tt0369610  imdbDisplay          NaN                0.0  \n",
      "tt0369610          NaN  short title                0.0  \n",
      "tt0369610  imdbDisplay          NaN                0.0  \n",
      "...                ...          ...                ...  \n",
      "tt9827784     original          NaN                1.0  \n",
      "tt9827784  imdbDisplay          NaN                0.0  \n",
      "tt9880178     original          NaN                1.0  \n",
      "tt9880178          NaN          NaN                0.0  \n",
      "tt9880178  imdbDisplay          NaN                0.0  \n",
      "\n",
      "[331703 rows x 7 columns]\n",
      "                                                 studio  domestic_gross  \\\n",
      "title                                                                     \n",
      "Toy Story 3                                          BV     415000000.0   \n",
      "Alice in Wonderland (2010)                           BV     334200000.0   \n",
      "Harry Potter and the Deathly Hallows Part 1          WB     296000000.0   \n",
      "Inception                                            WB     292600000.0   \n",
      "Shrek Forever After                                P/DW     238700000.0   \n",
      "...                                                 ...             ...   \n",
      "The Quake                                         Magn.          6200.0   \n",
      "Edward II (2018 re-release)                          FM          4800.0   \n",
      "El Pacto                                           Sony          2500.0   \n",
      "The Swan                                     Synergetic          2400.0   \n",
      "An Actor Prepares                                 Grav.          1700.0   \n",
      "\n",
      "                                            foreign_gross  year  \n",
      "title                                                            \n",
      "Toy Story 3                                     652000000  2010  \n",
      "Alice in Wonderland (2010)                      691300000  2010  \n",
      "Harry Potter and the Deathly Hallows Part 1     664300000  2010  \n",
      "Inception                                       535700000  2010  \n",
      "Shrek Forever After                             513900000  2010  \n",
      "...                                                   ...   ...  \n",
      "The Quake                                             NaN  2018  \n",
      "Edward II (2018 re-release)                           NaN  2018  \n",
      "El Pacto                                              NaN  2018  \n",
      "The Swan                                              NaN  2018  \n",
      "An Actor Prepares                                     NaN  2018  \n",
      "\n",
      "[3387 rows x 4 columns]\n",
      "                                         primary_title  \\\n",
      "tconst                                                   \n",
      "tt0063540                                    Sunghursh   \n",
      "tt0066787              One Day Before the Rainy Season   \n",
      "tt0069049                   The Other Side of the Wind   \n",
      "tt0069204                              Sabse Bada Sukh   \n",
      "tt0100275                     The Wandering Soap Opera   \n",
      "...                                                ...   \n",
      "tt9916538                          Kuambil Lagi Hatiku   \n",
      "tt9916622  Rodolpho Te√≥philo - O Legado de um Pioneiro   \n",
      "tt9916706                              Dankyavar Danka   \n",
      "tt9916730                                       6 Gunn   \n",
      "tt9916754               Chico Albuquerque - Revela√ß√µes   \n",
      "\n",
      "                                        original_title  start_year  \\\n",
      "tconst                                                               \n",
      "tt0063540                                    Sunghursh        2013   \n",
      "tt0066787                              Ashad Ka Ek Din        2019   \n",
      "tt0069049                   The Other Side of the Wind        2018   \n",
      "tt0069204                              Sabse Bada Sukh        2018   \n",
      "tt0100275                        La Telenovela Errante        2017   \n",
      "...                                                ...         ...   \n",
      "tt9916538                          Kuambil Lagi Hatiku        2019   \n",
      "tt9916622  Rodolpho Te√≥philo - O Legado de um Pioneiro        2015   \n",
      "tt9916706                              Dankyavar Danka        2013   \n",
      "tt9916730                                       6 Gunn        2017   \n",
      "tt9916754               Chico Albuquerque - Revela√ß√µes        2013   \n",
      "\n",
      "           runtime_minutes                genres  \n",
      "tconst                                            \n",
      "tt0063540            175.0    Action,Crime,Drama  \n",
      "tt0066787            114.0       Biography,Drama  \n",
      "tt0069049            122.0                 Drama  \n",
      "tt0069204              NaN          Comedy,Drama  \n",
      "tt0100275             80.0  Comedy,Drama,Fantasy  \n",
      "...                    ...                   ...  \n",
      "tt9916538            123.0                 Drama  \n",
      "tt9916622              NaN           Documentary  \n",
      "tt9916706              NaN                Comedy  \n",
      "tt9916730            116.0                   NaN  \n",
      "tt9916754              NaN           Documentary  \n",
      "\n",
      "[146144 rows x 5 columns]\n",
      "            averagerating  numvotes\n",
      "tconst                             \n",
      "tt10356526            8.3        31\n",
      "tt10384606            8.9       559\n",
      "tt1042974             6.4        20\n",
      "tt1043726             4.2     50352\n",
      "tt1060240             6.5        21\n",
      "...                   ...       ...\n",
      "tt9805820             8.1        25\n",
      "tt9844256             7.5        24\n",
      "tt9851050             4.7        14\n",
      "tt9886934             7.0         5\n",
      "tt9894098             6.3       128\n",
      "\n",
      "[73856 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check Values to make sure data is stored correctly\n",
    "for value in files_dict.values():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL Database for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already imported Sqlite3 so we can go ahead and create a table\n",
    "conn = sqlite3.connect(\"movies_db.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_sql_table_from_df(df, name, conn):\n",
    "    # Use try except\n",
    "    # it will try to make a table\n",
    "    # if a table exists the except part of the code will stop the program from making duplicates\n",
    "    try:\n",
    "        df.to_sql(name, conn)\n",
    "        print(f\"Created table {name}\")\n",
    "    \n",
    "    # if the table exists t will tell you, and won't cause an error\n",
    "    except Exception as e:\n",
    "        print(f\"could not make table {name}\")\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not make table tmdb_movies\n",
      "Table 'tmdb_movies' already exists.\n",
      "could not make table tn_movie_budgets\n",
      "Table 'tn_movie_budgets' already exists.\n",
      "could not make table imdb_name_basics\n",
      "Table 'imdb_name_basics' already exists.\n",
      "could not make table imdb_title_principals\n",
      "Table 'imdb_title_principals' already exists.\n",
      "could not make table title_akas\n",
      "Table 'title_akas' already exists.\n",
      "could not make table bom_movie_gross\n",
      "Table 'bom_movie_gross' already exists.\n",
      "could not make table imdb_title_basics\n",
      "Table 'imdb_title_basics' already exists.\n",
      "could not make table title_ratings\n",
      "Table 'title_ratings' already exists.\n"
     ]
    }
   ],
   "source": [
    "for name, table in files_dict.items():\n",
    "    create_sql_table_from_df(table, name, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tmdb_movies',),\n",
       " ('tn_movie_budgets',),\n",
       " ('imdb_name_basics',),\n",
       " ('imdb_title_principals',),\n",
       " ('imdb_title_akas',),\n",
       " ('title_akas',),\n",
       " ('bom_movie_gross',),\n",
       " ('imdb_title_basics',),\n",
       " ('title_ratings',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tables for accuracy\n",
    "conn.execute('''SELECT name\n",
    "                FROM sqlite_master \n",
    "                WHERE type='table';\n",
    "                ''').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
